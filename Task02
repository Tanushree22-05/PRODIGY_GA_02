!pip install transformers diffusers
!pip install torch
from transformers import DalleBartProcessor, DalleBartForConditionalGeneration
import torch
from PIL import Image
import matplotlib.pyplot as plt

# Load the DALL-E-mini model and processor
model_name = "dalle-mini/dalle-mini"
processor = DalleBartProcessor.from_pretrained(model_name)
model = DalleBartForConditionalGeneration.from_pretrained(model_name)

# Define the text prompt
text_prompt = "A futuristic cityscape with flying cars"

# Tokenize the text prompt
inputs = processor([text_prompt], return_tensors="pt")

# Generate images
outputs = model.generate(**inputs, max_length=50)

# Decode the generated images
images = processor.batch_decode(outputs, skip_special_tokens=True)

# Display the images
for image in images:
    img = Image.open(image)
    plt.imshow(img)
    plt.axis("off")
    plt.show()
from diffusers import StableDiffusionPipeline
import torch

# Load the Stable Diffusion model
model_id = "CompVis/stable-diffusion-v1-4"
pipeline = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)
pipeline = pipeline.to("cuda")

# Define the text prompt
text_prompt = "A futuristic cityscape with flying cars"

# Generate images
images = pipeline(text_prompt, num_inference_steps=50, guidance_scale=7.5).images

# Display the images
for image in images:
    image.show()
